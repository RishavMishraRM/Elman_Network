{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_input=15\n",
    "num_hidden=9\n",
    "num_output=12\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### step1: load data\n",
    "x_train =[\n",
    "[0.2452, 0.1466, 0.1314, 0.2243, 0.5523, 0.6642, 0.7015, 0.6981, 0.6821, 0.6945, 0.7549, 0.8215, 0.2394, 0.3214, 1],\n",
    "[0.2217, 0.1581, 0.1408, 0.2304, 0.5134, 0.5312, 0.6819, 0.7125, 0.7265, 0.6847, 0.7826, 0.8325, 0.2415, 0.3027, 0],\n",
    "[0.2525, 0.1627, 0.1507, 0.2406, 0.5502, 0.5636, 0.7051, 0.7352, 0.7459, 0.7015, 0.8064, 0.8156, 0.2385, 0.3125, 0],\n",
    "[0.2016, 0.1105, 0.1243, 0.1978, 0.5021, 0.5232, 0.6819, 0.6952, 0.7015, 0.6825, 0.7825, 0.7895, 0.2216, 0.2701, 1],\n",
    "[0.2115, 0.1201, 0.1312, 0.2019, 0.5532, 0.5736, 0.7029, 0.7032, 0.7189, 0.7019, 0.7965, 0.8025, 0.2352, 0.2506, 0.5],\n",
    "[0.2335, 0.1322, 0.1534, 0.2214, 0.5662, 0.5827, 0.7198, 0.7276, 0.7359, 0.7506, 0.8092, 0.8221, 0.2542, 0.3125, 0],\n",
    "[0.2368, 0.1432, 0.1653, 0.2205, 0.5823, 0.5971, 0.7136, 0.7129, 0.7263, 0.7153, 0.8091, 0.8217, 0.2601, 0.3198, 0],\n",
    "[0.2342, 0.1368, 0.1602, 0.2131, 0.5726, 0.5822, 0.7101, 0.7098, 0.7127, 0.7121, 0.7995, 0.8126, 0.2579, 0.3099, 0],\n",
    "[0.2113, 0.1212, 0.1305, 0.1819, 0.4952, 0.5312, 0.6886, 0.6898, 0.6999, 0.7323, 0.7721, 0.7956, 0.2301, 0.2867, 0.5],\n",
    "[0.2005, 0.1121, 0.1207, 0.1605, 0.4556, 0.5022, 0.6553, 0.6673, 0.6798, 0.7023, 0.7521, 0.7756, 0.2234, 0.2799, 1]\n",
    "]\n",
    "#print (x_train[0])\n",
    "#print(np.reshape(x_train[0],(1,15)))\n",
    "y_train = [\n",
    "[0.2217, 0.1581, 0.1408, 0.2304, 0.5134, 0.5312, 0.6819, 0.7125, 0.7265, 0.6847, 0.7826, 0.8325],\n",
    "[0.2525, 0.1627, 0.1507, 0.2406, 0.5502, 0.5636, 0.7051, 0.7352, 0.7459, 0.7015, 0.8064, 0.8156],\n",
    "[0.2016, 0.1105, 0.1243, 0.1978, 0.5021, 0.5232, 0.6819, 0.6952, 0.7015, 0.6825, 0.7825, 0.7895],\n",
    "[0.2115, 0.1201, 0.1312, 0.2019, 0.5532, 0.5736, 0.7029, 0.7032, 0.7189, 0.7019, 0.7965, 0.8025],\n",
    "[0.2335, 0.1322, 0.1534, 0.2214, 0.5662, 0.5827, 0.7198, 0.7276, 0.7359, 0.7506, 0.8092, 0.8221],\n",
    "[0.2368, 0.1432, 0.1653, 0.2205, 0.5823, 0.5971, 0.7136, 0.7129, 0.7263, 0.7153, 0.8091, 0.8217],\n",
    "[0.2342, 0.1368, 0.1602, 0.2131, 0.5726, 0.5822, 0.7101, 0.7098, 0.7127, 0.7121, 0.7995, 0.8126],\n",
    "[0.2113, 0.1212, 0.1305, 0.1819, 0.4952, 0.5312, 0.6886, 0.6898, 0.6999, 0.7323, 0.7721, 0.7956],\n",
    "[0.2005, 0.1121, 0.1207, 0.1605, 0.4556, 0.5022, 0.6553, 0.6673, 0.6798, 0.7023, 0.7521, 0.7756],\n",
    "[0.2123, 0.1257, 0.1343, 0.2079, 0.5579, 0.5716, 0.7059, 0.7145, 0.7205, 0.7401, 0.8019, 0.8316]\n",
    "]\n",
    "\n",
    "x_test =[0.2123, 0.1257, 0.1343, 0.2079, 0.5579, 0.5716, 0.7059, 0.7145, 0.7205, 0.7401, 0.8019, 0.8316, 0.2314, 0.2977, 0]\n",
    "y_test =[0.2119, 0.1215, 0.1621, 0.2161, 0.6171, 0.6159, 0.7115, 0.7201, 0.7243, 0.7298, 0.8179, 0.8229]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'hidden/weight_1:0' shape=(9,) dtype=float32_ref>\n",
      "Tensor(\"hidden/u_weight:0\", shape=(9, 9), dtype=float32)\n",
      "Tensor(\"hidden/activation:0\", shape=(1, 9), dtype=float32)\n",
      "<tf.Variable 'output/weight:0' shape=(9, 12) dtype=float32_ref>\n",
      "WARNING:tensorflow:From C:\\Users\\steph\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "loss  0.86336\n",
      "loss  0.00420244\n",
      "loss  0.00495149\n",
      "loss  0.0194202\n",
      "loss  0.00268286\n",
      "loss  0.0057089\n",
      "loss  0.00538438\n",
      "loss  0.00556995\n",
      "loss  0.00558003\n",
      "loss  0.00272677\n",
      "loss  0.00544751\n",
      "loss  0.00278414\n",
      "loss  0.00602423\n",
      "loss  0.0200737\n",
      "loss  0.0048188\n",
      "loss  0.00420232\n",
      "loss  0.00585103\n",
      "loss  0.00415776\n",
      "loss  0.00557575\n",
      "loss  0.0196201\n",
      "pridiction err  [[ 0.05307943  0.09173351 -0.12705341 -0.03365863 -0.12847887 -0.09384243\n",
      "  -0.01870823 -0.01893228 -0.00960315 -0.02405241 -0.03288684 -0.01650634]]\n",
      "mean pridiction err  0.0540446\n"
     ]
    }
   ],
   "source": [
    "### step2: build Elman network\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name='weight')\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.01, shape=shape)\n",
    "    return tf.Variable(initial, name='bias')\n",
    "\n",
    "## 新建一个graph\n",
    "with tf.Graph().as_default():\n",
    "    with tf.name_scope('input'):\n",
    "        x = tf.placeholder(tf.float32, shape=[1,num_input],name = 'input')\n",
    "        \n",
    "    with tf.name_scope('hidden'):\n",
    "        h_old = tf.placeholder(tf.float32, shape=[1,num_hidden], name = 'hidden_old')\n",
    "        w = weight_variable([num_input, num_hidden])\n",
    "        u_pre = weight_variable([num_hidden])   #1 dimentional tensor\n",
    "        print (u_pre)\n",
    "        u = tf.diag(u_pre, name='u_weight')  #变换成对角矩阵\n",
    "        print (u)\n",
    "        b = bias_variable([1,num_hidden])\n",
    "        h_new = tf.sigmoid(tf.matmul(x, w) + tf.matmul(h_old,u) + b, name='activation')\n",
    "        #h_new = tf.nn.relu(tf.matmul(x, w) + tf.matmul(h_old,u) + b)\n",
    "        print (h_new)\n",
    "\n",
    "    with tf.name_scope('output'):\n",
    "        y_golden = tf.placeholder(tf.float32, shape=[1,num_output], name='output_golden')\n",
    "        w = weight_variable([num_hidden, num_output])\n",
    "        print (w)\n",
    "        b = bias_variable([1,num_output])\n",
    "        y = tf.sigmoid(tf.matmul(h_new, w) + b, name='activation')\n",
    "        #y =  tf.nn.relu(tf.matmul(h_new, w) + b)\n",
    "        #y = tf.matmul(h_new, w) + b\n",
    "        #print (y)\n",
    "\n",
    "    loss = tf.reduce_sum(tf.square(y_golden - y))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    #optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    test_accuracy = (y-y_test)/y_test\n",
    "    test_accuracy_mean = tf.reduce_sum(tf.abs(test_accuracy))/num_output\n",
    "    \n",
    "    # merge summary\n",
    "    summary_op = tf.summary.merge_all()\n",
    "    \n",
    "    init = tf.initialize_all_variables()\n",
    "    \n",
    "    ### step3: training\n",
    "    with tf.Session() as session:   #在这个graph里面打开session\n",
    "        ## 必须先做初始化\n",
    "        session.run(init)\n",
    "        \n",
    "        ## 写入summary，用tensorboard查看graph\n",
    "        train_writer = tf.summary.FileWriter(\"./power/logs/elman/\", session.graph)\n",
    "    \n",
    "        h_old_initial = [[0.01]*num_hidden]\n",
    "        #print (h_old_initial)\n",
    "    \n",
    "        steps = 20000\n",
    "        #cur_pattern = np.random.randint(0, 5)\n",
    "        cur_pattern = 0\n",
    "    \n",
    "        ## feed初始化，给所有placeholder传值，给hidden layer的结果传0\n",
    "        feed = {\n",
    "                x : np.reshape(x_train[cur_pattern],(1,num_input)),\n",
    "                y_golden : np.reshape(y_train[cur_pattern],(1,num_output)),\n",
    "                h_old: h_old_initial\n",
    "        }\n",
    "    \n",
    "        for i in range(steps):\n",
    "            ## 随机选择输入pattern\n",
    "            cur_pattern = np.random.randint(0, 10)\n",
    "            #cur_pattern = i%5\n",
    "        \n",
    "            ## run 优化器\n",
    "            session.run(optimizer,feed_dict=feed)\n",
    "            \n",
    "            ## 取出hidden layer的结果，用来做循环\n",
    "            h_new_fetched,u_fetched = session.run([h_new,u], feed_dict=feed)\n",
    "            #print (h_new_fetched)\n",
    "            #print (np.reshape(h_new_fetched,(1,num_hidden)))\n",
    "        \n",
    "            ## 把hidden layer结果传回去\n",
    "            feed = {\n",
    "                    x: np.reshape(x_train[cur_pattern],(1,num_input)),\n",
    "                    y_golden: np.reshape(y_train[cur_pattern],(1,num_output)),\n",
    "                    h_old: np.reshape(h_new_fetched,(1,num_hidden))\n",
    "            }  \n",
    "            \n",
    "            if i%1000 == 0:\n",
    "                print('loss ', session.run(loss, feed_dict=feed))\n",
    "                #print('u', u_fetched)\n",
    "                \n",
    "        #检验训练结果\n",
    "        feed = {\n",
    "                x: np.reshape(x_test,(1,num_input)),\n",
    "                y_golden: np.reshape(y_test,(1,num_output)),\n",
    "                h_old: np.reshape(h_new_fetched,(1,num_hidden))\n",
    "        }       \n",
    "        test_accuracy_fetched, test_accuracy_mean_fetched=session.run([test_accuracy,test_accuracy_mean],feed_dict=feed)\n",
    "        print ('pridiction err ',test_accuracy_fetched)\n",
    "        print ('mean pridiction err ',test_accuracy_mean_fetched)\n",
    "        \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n### step1: load data\\nx_train =[\\n    [0.2113, 0.1212, 0.1305, 0.1819, 0.4952, 0.5312, 0.6886, 0.6898, 0.6999, 0.7323, 0.7721, 0.7956, 0.2234, 0.2799, 1],\\n    [0.2005, 0.1121, 0.1207, 0.1605, 0.4556, 0.5002, 0.6553, 0.6673, 0.6798, 0.7023, 0.7521, 0.7756, 0.2314, 0.2977, 0],\\n    [0.2342, 0.1368, 0.1602, 0.2131, 0.5726, 0.5822, 0.7101, 0.7098, 0.7127, 0.7121, 0.7995, 0.8126, 0.2301, 0.2867, 0.5],\\n    [0.2368, 0.1432, 0.1653, 0.2205, 0.5823, 0.5971, 0.7136, 0.7129, 0.7263, 0.7153, 0.8091, 0.8217, 0.2579, 0.3099, 0],\\n    [0.2335, 0.1322, 0.1534, 0.2214, 0.5623, 0.5727, 0.7198, 0.7276, 0.7359, 0.7506, 0.8092, 0.8221, 0.2601, 0.3198, 0]\\n]\\n#print (x_train[0])\\n#print(np.reshape(x_train[0],(1,15)))\\ny_train = [\\n    [0.2005, 0.1121, 0.1207, 0.1605, 0.4556, 0.5002, 0.6553, 0.6673, 0.6798, 0.7023, 0.7521, 0.7756],\\n    [0.2342, 0.1368, 0.1602, 0.2131, 0.5726, 0.5822, 0.7101, 0.7098, 0.7127, 0.7121, 0.7995, 0.8126],\\n    [0.2368, 0.1432, 0.1653, 0.2205, 0.5823, 0.5971, 0.7136, 0.7129, 0.7263, 0.7153, 0.8091, 0.8217],\\n    [0.2335, 0.1322, 0.1534, 0.2214, 0.5623, 0.5727, 0.7198, 0.7276, 0.7359, 0.7506, 0.8092, 0.8221],\\n    [0.2115, 0.1201, 0.1312, 0.2019, 0.5532, 0.5736, 0.7029, 0.7032, 0.7189, 0.7019, 0.7965, 0.8025]\\n]\\n\\nx_test =[0.2115, 0.1201, 0.1312, 0.2019, 0.5532, 0.5736, 0.7029, 0.7032, 0.7189, 0.7019, 0.7965, 0.8025, 0.2542, 0.3125, 0]\\ny_test =[0.2016, 0.1105, 0.1243, 0.1978, 0.5021, 0.5232, 0.6819, 0.6952, 0.7015, 0.6825, 0.7825, 0.7895]\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "### step1: load data\n",
    "x_train =[\n",
    "    [0.2113, 0.1212, 0.1305, 0.1819, 0.4952, 0.5312, 0.6886, 0.6898, 0.6999, 0.7323, 0.7721, 0.7956, 0.2234, 0.2799, 1],\n",
    "    [0.2005, 0.1121, 0.1207, 0.1605, 0.4556, 0.5002, 0.6553, 0.6673, 0.6798, 0.7023, 0.7521, 0.7756, 0.2314, 0.2977, 0],\n",
    "    [0.2342, 0.1368, 0.1602, 0.2131, 0.5726, 0.5822, 0.7101, 0.7098, 0.7127, 0.7121, 0.7995, 0.8126, 0.2301, 0.2867, 0.5],\n",
    "    [0.2368, 0.1432, 0.1653, 0.2205, 0.5823, 0.5971, 0.7136, 0.7129, 0.7263, 0.7153, 0.8091, 0.8217, 0.2579, 0.3099, 0],\n",
    "    [0.2335, 0.1322, 0.1534, 0.2214, 0.5623, 0.5727, 0.7198, 0.7276, 0.7359, 0.7506, 0.8092, 0.8221, 0.2601, 0.3198, 0]\n",
    "]\n",
    "#print (x_train[0])\n",
    "#print(np.reshape(x_train[0],(1,15)))\n",
    "y_train = [\n",
    "    [0.2005, 0.1121, 0.1207, 0.1605, 0.4556, 0.5002, 0.6553, 0.6673, 0.6798, 0.7023, 0.7521, 0.7756],\n",
    "    [0.2342, 0.1368, 0.1602, 0.2131, 0.5726, 0.5822, 0.7101, 0.7098, 0.7127, 0.7121, 0.7995, 0.8126],\n",
    "    [0.2368, 0.1432, 0.1653, 0.2205, 0.5823, 0.5971, 0.7136, 0.7129, 0.7263, 0.7153, 0.8091, 0.8217],\n",
    "    [0.2335, 0.1322, 0.1534, 0.2214, 0.5623, 0.5727, 0.7198, 0.7276, 0.7359, 0.7506, 0.8092, 0.8221],\n",
    "    [0.2115, 0.1201, 0.1312, 0.2019, 0.5532, 0.5736, 0.7029, 0.7032, 0.7189, 0.7019, 0.7965, 0.8025]\n",
    "]\n",
    "\n",
    "x_test =[0.2115, 0.1201, 0.1312, 0.2019, 0.5532, 0.5736, 0.7029, 0.7032, 0.7189, 0.7019, 0.7965, 0.8025, 0.2542, 0.3125, 0]\n",
    "y_test =[0.2016, 0.1105, 0.1243, 0.1978, 0.5021, 0.5232, 0.6819, 0.6952, 0.7015, 0.6825, 0.7825, 0.7895]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
